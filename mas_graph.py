import sys
import os
import json
from typing import List, Dict, Any, TypedDict, NotRequired
from operator import itemgetter
from concurrent.futures import ThreadPoolExecutor, as_completed

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()

from langgraph.graph import StateGraph, END
# from langgraph.checkpoint.memory import MemorySaver  # åœ¨LangGraph Cloudä¸­ä¸éœ€è¦ï¼Œä¼šè‡ªåŠ¨æä¾›
from langchain_core.messages import AIMessage, HumanMessage, BaseMessage

# from sampler.chat_completion_sampler import ChatCompletionSampler
# from sampler.o_chat_completion_sampler import OChatCompletionSampler
# from sampler.together_completion_sampler import ChatCompletionSampler as ToChatCompletionSampler
# from sampler.vllm_completion_sampler import ChatCompletionSampler as VllmChatCompletionSampler
from sampler.factory import SamplerFactory # å¯¼å…¥æ–°çš„é‡‡æ ·å™¨å·¥å‚
from blocks import create_block
from utils import extract_xml
from common import AgentState, EmotionalState, MasAgentOutput

# æ¨¡å‹åç§°ç°åœ¨å°†ä»å›¾çŠ¶æ€(GraphState)ä¸­è¯»å–ï¼Œè¯¥çŠ¶æ€åœ¨åˆå§‹åŒ–æ—¶ä»ç¯å¢ƒå˜é‡åŠ è½½
# node_model = "gpt-4o_chatgpt"
# feedback_model = "gpt-4o_chatgpt"

# ä½¿ç”¨æ–°çš„ AgentState ä½œä¸ºå›¾çš„çŠ¶æ€
GraphState = AgentState

def initialize_state_node(state: GraphState) -> Dict[str, Any]:
    """
    ä¸ºçŠ¶æ€å›¾çš„é¦–æ¬¡è¿è¡Œæˆ–æ¯æ¬¡è¿­ä»£æä¾›æ‰€æœ‰å­—æ®µçš„é»˜è®¤å€¼ã€‚
    ç¡®ä¿æ‰€æœ‰éœ€è¦çš„é”®éƒ½å­˜åœ¨ï¼Œå³ä½¿å®ƒä»¬æ˜¯ç©ºçš„ã€‚
    """
    if state is None:
        state = {}

    # åˆ›å»ºä¸€ä¸ªå…¨æ–°çš„çŠ¶æ€å‰¯æœ¬ï¼Œä»¥ç¡®ä¿æ•°æ®åœ¨å›¾çš„æ‰§è¡Œè¿‡ç¨‹ä¸­æŒä¹…å­˜åœ¨
    persisted_state = state.copy()

    # --- æ ¸å¿ƒæ”¹åŠ¨ï¼šå¤„ç† user_input ---
    # å°†å•æ¬¡çš„ user_input è½¬æ¢ä¸º HumanMessageï¼Œå‡†å¤‡è®© add_messages è¿½åŠ 
    new_messages_to_add = []
    if user_input := persisted_state.pop("user_input", None):
        new_messages_to_add.append(HumanMessage(content=user_input))

    # å½’ä¸€åŒ–å·²æœ‰çš„æ¶ˆæ¯æ ¼å¼ï¼ˆåœ¨ä»æ£€æŸ¥ç‚¹åŠ è½½æ—¶å¯èƒ½éœ€è¦ï¼‰
    raw_messages = persisted_state.get("messages", [])
    normalized_messages = []
    for msg in raw_messages:
        if isinstance(msg, BaseMessage):
            normalized_messages.append(msg)
        elif isinstance(msg, dict):
            # å¤„ç†é€šè¿‡APIç­‰æ–¹å¼ä¼ å…¥çš„ã€è¢«åºåˆ—åŒ–ä¸ºå­—å…¸çš„æ¶ˆæ¯
            role = msg.get("role", "").lower()
            content = msg.get("content", "")
            if role in ["human", "user"]:
                normalized_messages.append(HumanMessage(content=content))
            elif role in ["ai", "assistant"]:
                normalized_messages.append(AIMessage(content=content))
    
    # å°†å½’ä¸€åŒ–åçš„å†å²æ¶ˆæ¯æ”¾å›æŒä¹…åŒ–çŠ¶æ€ï¼Œå¹¶è¿½åŠ æ–°çš„æ¶ˆæ¯
    persisted_state["messages"] = normalized_messages + new_messages_to_add

    # ä½¿ç”¨ .get() å®‰å…¨åœ°è®¿é—®å¹¶ä¸ºæˆ‘ä»¬æ¨¡å‹çš„æ ¸å¿ƒå­—æ®µæä¾›é»˜è®¤å€¼
    initialized_state = {
        **persisted_state, # å°†æ‰€æœ‰å·²æœ‰å­—æ®µå¸¦å…¥æ–°çŠ¶æ€
        # messages å­—æ®µå·²ç»åœ¨ persisted_state ä¸­æ›´æ–°ï¼Œæ— éœ€å†æ¬¡è¦†ç›–
        "current_stage": persisted_state.get("current_stage", "initial_contact"),
        "emotional_state": persisted_state.get("emotional_state", EmotionalState()),
        "user_profile": persisted_state.get("user_profile", {}),
        "turn_count": persisted_state.get("turn_count", 0),
        
        # ä¸ºä»æ—§GraphStateåˆå¹¶è¿‡æ¥çš„å­—æ®µæä¾›é»˜è®¤å€¼
        "internal_monologue": [], # æ€»æ˜¯é‡ç½®å†…å¿ƒç‹¬ç™½
        "candidate_actions": [],  # æ€»æ˜¯é‡ç½®å€™é€‰è¡ŒåŠ¨
        "evaluated_responses": [],# æ€»æ˜¯é‡ç½®è¯„ä¼°è¿‡çš„å“åº”
        "final_response": "",     # æ€»æ˜¯é‡ç½®æœ€ç»ˆå“åº”
        "last_message": "",       # é‡ç½®APIè¾“å‡ºæ¶ˆæ¯
        "agent_temperature": persisted_state.get("agent_temperature", 0.5),
        "node_model": persisted_state.get("node_model", os.environ.get("NODE_MODEL", "o3")),
        "feedback_model": persisted_state.get("feedback_model", os.environ.get("FEEDBACK_MODEL", "o3")),
        "verbose": persisted_state.get("verbose", False), 
        # é»˜è®¤å…³é—­è°ƒè¯•æ¨¡å¼,éœ€è¦è¿›è¡Œå›å¤ç­–ç•¥çš„åˆ†ææ—¶ï¼Œåªéœ€è¦åœ¨messageså­—æ®µåæ·»åŠ "verbose": True
        
        # æ–°å¢ï¼šè¡Œä¸ºæ„å›¾å’Œé¢„çº¦ç®¡ç†å­—æ®µ
        "customer_intent": persisted_state.get("customer_intent"),
        "appointment_info": persisted_state.get("appointment_info"),
    }

    # å¢åŠ å¯¹è¯è½®æ¬¡
    initialized_state["turn_count"] += 1

    # æ¸…ç†è¿è¡Œæ—¶çŠ¶æ€ï¼ˆè¿™ä¸€æ­¥ç°åœ¨é€šè¿‡ä¸Šé¢çš„é‡ç½®æ¥å®Œæˆï¼Œæ³¨é‡Šæ‰ä»¥é¿å…å†—ä½™ï¼‰
    # initialized_state["internal_monologue"] = []
    # initialized_state["candidate_actions"] = []
    # initialized_state["evaluated_responses"] = []
    # initialized_state["final_response"] = ""


    return initialized_state

def _format_messages(messages: List[Any]) -> str:
    """å°† LangChain BaseMessage å¯¹è±¡çš„åˆ—è¡¨æ ¼å¼åŒ–ä¸ºå•ä¸ªå­—ç¬¦ä¸²ã€‚"""
    if not messages:
        return "ï¼ˆæ— å†å²è®°å½•ï¼‰"
    
    formatted_string = ""
    for message in messages:
        # message.type åœ¨ BaseMessage å¯¹è±¡ä¸­æ˜¯ 'human', 'ai', 'system' ç­‰
        role = "å®¢æˆ·" if message.type == "human" else "æ—åŒ»ç”Ÿ"
        formatted_string += f"{role}: {message.content}\n"
    return formatted_string.strip()

def analyze_sentiment_node(state: GraphState) -> Dict[str, Any]:
    """
    æ ¹æ®å½“å‰çš„æƒ…æ„ŸçŠ¶æ€ï¼ŒåŠ¨æ€è®¾ç½®åŠ©æ‰‹çš„æ¸©åº¦ï¼ˆåˆ›é€ æ€§ï¼‰ã€‚
    å‰æœŸå…¶å®å¯ä»¥ä¸ç”¨è¿™ä¸ªæ¨¡å—7/3
    """
    internal_monologue = state.get("internal_monologue", [])
    emotional_state = state.get("emotional_state") # æˆ‘ä»¬ä»è¿™é‡Œè·å–æƒ…æ„Ÿ
    verbose = state.get("verbose", False)

    if not emotional_state:
        # å¦‚æœæ²¡æœ‰æƒ…æ„ŸçŠ¶æ€ï¼Œä½¿ç”¨é»˜è®¤æ¸©åº¦
        return {"agent_temperature": 0.6}

    # åŸºäºèˆ’é€‚åº¦å’Œç†Ÿæ‚‰åº¦æ¥è®¾å®šæ¸©åº¦
    # å¦‚æœç”¨æˆ·æ„Ÿåˆ°èˆ’é€‚å’Œé«˜å…´ï¼Œæˆ‘ä»¬è¯´è¯çš„æ–¹å¼å°±ä¼šæ›´æ´»æ³¼ï¼Œæ›´åƒæœ‹å‹ã€‚
    #ä½†å…¶å®è¿™éƒ¨åˆ†ï¼Œåº”è¯¥åœ¨æ¨¡å‹æ•²å®šåå†åšè¯„ä¼°ï¼Œå› ä¸ºæ¯ä¸ªæ¨¡å‹çš„é£æ ¼å¹¶ä¸åŒã€‚
    comfort = emotional_state.comfort_level
    familiarity = emotional_state.familiarity_level
    
    agent_temperature = 0.6 # é»˜è®¤å€¼ï¼Œqwenä½¿ç”¨ä½æ¸©ï¼Œé¿å…è¿‡åº¦æ´»è·ƒ
    if comfort > 0.6 and familiarity > 0.5:
        agent_temperature = 0.6 # æ›´å¯Œåˆ›é€ æ€§ã€æ›´åƒæœ‹å‹
    elif comfort < 0.3:
        agent_temperature = 0.6 # æ›´ä¿å®ˆã€æ›´è°¨æ…

    new_monologue = internal_monologue + [f"æ¸©åº¦è®¾å®šï¼šæ ¹æ®å½“å‰æƒ…æ„Ÿ (èˆ’é€‚åº¦:{comfort:.2f}, ç†Ÿæ‚‰åº¦:{familiarity:.2f})ï¼Œè®¾å®šæ¸©åº¦ä¸º {agent_temperature}ã€‚"]
    
    # åªåœ¨verboseæ¨¡å¼ä¸‹è¾“å‡ºè°ƒè¯•ä¿¡æ¯
    if verbose:
        print(f"[DEBUG] æƒ…æ„Ÿåˆ†æèŠ‚ç‚¹: æ¸©åº¦è®¾å®šä¸º {agent_temperature}")
    
    return {
        "agent_temperature": agent_temperature,
        "internal_monologue": new_monologue,
    }

def _design_node(state: GraphState) -> Dict[str, Any]:
    """
    æ™ºèƒ½å†³ç­–èŠ‚ç‚¹ï¼Œé‡æ–°è®¾è®¡ä¸ºæœåŠ¡å¯¼å‘è€Œéé”€å”®å¯¼å‘ã€‚
    å…è®¸"æ­£ç¡®çš„ç¼ºç‚¹"ï¼Œè¡¨ç°å¾—æ›´åŠ è‡ªç„¶å’Œäººæ€§åŒ–ã€‚
    """
    internal_monologue = state.get("internal_monologue", [])
    verbose = state.get("verbose", False)
    
    # 1. è°ƒç”¨çŠ¶æ€è¯„ä¼°å™¨ï¼Œè·å–æœ€æ–°çš„æƒ…æ„ŸçŠ¶æ€
    from blocks.state_evaluator import evaluate_state
    from blocks.intent_analyzer import analyze_customer_intent, update_appointment_info
    
    # ç›´æ¥è°ƒç”¨çŠ¶æ€è¯„ä¼°
    evaluation_result = evaluate_state(state)
    
    # æ›´æ–°çŠ¶æ€ã€‚å¦‚æœè¯„ä¼°å¤±è´¥ï¼Œåˆ™ä½¿ç”¨æ—§çŠ¶æ€
    current_emotional_state = evaluation_result.get("emotional_state", state["emotional_state"])
    customer_intent = evaluation_result.get("customer_intent_level", state.get("customer_intent_level", "low"))
    
    # 2. æ–°å¢ï¼šåˆ†æå®¢æˆ·è¡Œä¸ºæ„å›¾
    intent_result = analyze_customer_intent(state)
    current_customer_intent = intent_result.get("customer_intent")
    
    # 3. æ–°å¢ï¼šæ›´æ–°é¢„çº¦ä¿¡æ¯
    appointment_updates = {}
    if current_customer_intent:
        appointment_updates = update_appointment_info(state, current_customer_intent)
    
    # åˆå¹¶é¢„çº¦ä¿¡æ¯æ›´æ–°
    current_appointment_info = state.get("appointment_info")
    if appointment_updates.get("appointment_info"):
        current_appointment_info = appointment_updates["appointment_info"]
    
    internal_monologue.append(f"æƒ…æ„Ÿè¯„ä¼°å®Œæˆ: {current_emotional_state.model_dump_json()}")
    internal_monologue.append(f"å®¢æˆ·æ„å‘è¯„ä¼°: {customer_intent}")
    if current_customer_intent:
        internal_monologue.append(f"è¡Œä¸ºæ„å›¾è¯†åˆ«: {current_customer_intent.intent_type} (ç½®ä¿¡åº¦: {current_customer_intent.confidence:.2f})")
        if current_customer_intent.extracted_info:
            internal_monologue.append(f"æå–ä¿¡æ¯: {current_customer_intent.extracted_info}")
    if current_appointment_info:
        internal_monologue.append(f"é¢„çº¦çŠ¶æ€: {current_appointment_info.appointment_status}, æ—¶é—´: {current_appointment_info.preferred_time or 'æœªå®š'}")
    
    if verbose:
        print(f"[DEBUG] ç­–ç•¥è®¾è®¡èŠ‚ç‚¹: å®¢æˆ·æ„å‘={customer_intent}, ä¿¡ä»»åº¦={current_emotional_state.trust_level:.2f}")
    
    # 2. æ”¹è¿›å¯¹è¯é˜¶æ®µ - æ›´è‡ªç„¶çš„æ¨è¿›é€»è¾‘
    current_stage = state["current_stage"]
    trust_level = current_emotional_state.trust_level
    comfort_level = current_emotional_state.comfort_level
    familiarity_level = current_emotional_state.familiarity_level
    turn_count = state.get("turn_count", 0)
    
    new_stage = current_stage # é»˜è®¤ä¿æŒå½“å‰é˜¶æ®µ
    
    # æ”¹è¿›çš„é˜¶æ®µæ¨è¿›é€»è¾‘ï¼ˆä¿æŒåŸæœ‰é˜¶æ®µåç§°ï¼‰
    if current_stage == "initial_contact":
        # é˜¶æ®µ1ï¼šåˆæ¬¡æ¥è§¦ - è‡ªç„¶é—®å€™ï¼Œå»ºç«‹åŸºç¡€è¿æ¥
        if turn_count >= 1 and comfort_level > 0.2:
            new_stage = "ice_breaking"
    elif current_stage == "ice_breaking":
        # é˜¶æ®µ2ï¼šè½»æ¾ç ´å†° - å»ºç«‹çœŸå®è¿æ¥ï¼Œå…è®¸"ç¼ºé™·"
        if familiarity_level > 0.3:
            new_stage = "subtle_expertise"
    elif current_stage == "subtle_expertise":
        # é˜¶æ®µ3ï¼šå±•ç¤ºä¸“ä¸š - å®¢è§‚å±•ç¤ºï¼Œéå¤¸å¤§å®£ä¼ 
        if trust_level > 0.4:
            new_stage = "pain_point_mining"
    elif current_stage == "pain_point_mining":
        # é˜¶æ®µ4ï¼šäº†è§£éœ€æ±‚ - çœŸè¯šè¯¢é—®ï¼Œéæ¨é”€å¼
        if trust_level > 0.6 and customer_intent in ["medium", "high"]:
            new_stage = "solution_visualization"
    elif current_stage == "solution_visualization":
        # é˜¶æ®µ5ï¼šè§£å†³æ–¹æ¡ˆ - ååŠ©å†³ç­–ï¼Œéå¼ºåˆ¶æ¨é”€
        if trust_level > 0.7 and customer_intent == "high":
            new_stage = "natural_invitation"
        
    # è‡ªç„¶å›é€€æœºåˆ¶ï¼šå¦‚æœå®¢æˆ·ä¸èˆ’æœï¼Œå›åˆ°æ›´è½»æ¾çš„é˜¶æ®µ
    if comfort_level < 0.3 and current_stage not in ["initial_contact", "ice_breaking"]:
        new_stage = "ice_breaking"  # è‡ªç„¶å›é€€åˆ°è½»æ¾ç ´å†°
        internal_monologue.append(f"æ£€æµ‹åˆ°èˆ’é€‚åº¦è¿‡ä½ ({comfort_level:.2f})ï¼Œè‡ªç„¶å›é€€åˆ°è½»æ¾ç ´å†°")
    elif trust_level < 0.2 and current_stage not in ["initial_contact"]:
        new_stage = "initial_contact"  # é‡æ–°å¼€å§‹
        internal_monologue.append(f"æ£€æµ‹åˆ°ä¿¡ä»»åº¦è¿‡ä½ ({trust_level:.2f})ï¼Œé‡æ–°å¼€å§‹å¯¹è¯")
        
    if new_stage != current_stage:
        internal_monologue.append(f"è‡ªç„¶æµç¨‹æ¨è¿›: '{current_stage}' â†’ '{new_stage}' (ä¿¡ä»»{trust_level:.2f}/èˆ’é€‚{comfort_level:.2f}/ç†Ÿæ‚‰{familiarity_level:.2f})")
    
    # 3. æ”¹è¿›åŠ¨ä½œå†³ç­– - åŸºäºç°æœ‰æ¨¡å—ï¼Œè®©è¡Œä¸ºæ›´è‡ªç„¶
    candidate_actions = []
    
    # ä¼˜å…ˆçº§1ï¼šå¤„ç†æ˜ç¡®çš„é¢„çº¦æ„å›¾
    if current_customer_intent and current_customer_intent.intent_type in ["appointment_request", "time_confirmation", "ready_to_book"]:
        if current_customer_intent.confidence > 0.8:
            # é«˜ç½®ä¿¡åº¦ï¼šä½¿ç”¨è‡ªç„¶é‚€çº¦
            candidate_actions = ["active_close", "value_display"]
            internal_monologue.append(f"æ£€æµ‹åˆ°æ˜ç¡®é¢„çº¦éœ€æ±‚ï¼Œè¿›è¡Œè‡ªç„¶é‚€çº¦")
        else:
            # ä½ç½®ä¿¡åº¦ï¼šå…ˆäº†è§£éœ€æ±‚
            candidate_actions = ["needs_analysis", "value_display"]
            internal_monologue.append(f"é¢„çº¦æ„å›¾ä¸æ˜ç¡®ï¼Œå…ˆäº†è§£å…·ä½“éœ€æ±‚")
    
    # ä¼˜å…ˆçº§2ï¼šå¤„ç†ä¿¡æ¯å’¨è¯¢
    elif current_customer_intent and current_customer_intent.intent_type == "info_seeking":
        # æ˜ç¡®éœ€æ±‚æ—¶ä¼˜å…ˆæä¾›ä¿¡æ¯ï¼Œè€Œä¸æ˜¯æŒ–æ˜éœ€æ±‚
        candidate_actions = ["value_display"]
        # åªæœ‰åœ¨æä¾›åŸºæœ¬ä¿¡æ¯åï¼Œæ‰è€ƒè™‘äº†è§£ç»†èŠ‚
        if familiarity_level > 0.4:  # å·²ç»æœ‰ä¸€å®šåŸºç¡€æ—¶æ‰è¯¢é—®ç»†èŠ‚
            candidate_actions.append("needs_analysis")
        internal_monologue.append(f"å®¢æˆ·å¯»æ±‚ä¿¡æ¯ï¼Œä¼˜å…ˆæä¾›é¡¹ç›®ä»‹ç»")
    
    # ä¼˜å…ˆçº§3ï¼šå¤„ç†ä»·æ ¼è¯¢é—®ï¼ˆçœŸå®å›åº”è€Œéé”€å”®è¯æœ¯ï¼‰
    elif current_customer_intent and current_customer_intent.intent_type == "price_inquiry":
        candidate_actions = ["value_display", "value_pitch"]
        if trust_level > 0.5:
            candidate_actions.append("active_close")  # é«˜ä¿¡ä»»æ—¶å¯ä»¥æ¨è¿›
        internal_monologue.append(f"ä»·æ ¼å’¨è¯¢ï¼Œæä¾›çœŸå®ä¿¡æ¯")
    
    # ä¼˜å…ˆçº§4ï¼šå¤„ç†é¡¾è™‘ï¼ˆç†è§£è€Œéåé©³ï¼‰
    elif current_customer_intent and current_customer_intent.intent_type == "concern_raised":
        candidate_actions = ["stress_response", "rapport_building"]
        if comfort_level < 0.4:
            candidate_actions.append("rapport_building")  # èˆ’é€‚åº¦ä½æ—¶é‡å»ºå…³ç³»
        internal_monologue.append(f"å®¢æˆ·æœ‰é¡¾è™‘ï¼Œç»™äºˆç†è§£å’Œç¼“è§£")
    
    # ä¼˜å…ˆçº§5ï¼šåŸºäºé˜¶æ®µçš„è‡ªç„¶å¯¹è¯æµç¨‹
    else:
        # æ ¹æ®å½“å‰é˜¶æ®µå†³å®šè‡ªç„¶å›åº”ç­–ç•¥
        if new_stage == "initial_contact":
            candidate_actions = ["greeting"]
        elif new_stage == "ice_breaking":
            candidate_actions = ["rapport_building"]
            # å¶å°”å…è®¸"ç¼ºé™·"ï¼šç®€çŸ­å›å¤
            if turn_count % 4 == 0:  # å¶å°”è¡¨ç°å¾—ä¸é‚£ä¹ˆå®Œç¾
                candidate_actions = ["rapport_building"]  # ä¿æŒç®€æ´
        elif new_stage == "subtle_expertise":
            candidate_actions = ["value_display"]
            if familiarity_level > 0.4:
                candidate_actions.append("needs_analysis")
        elif new_stage == "pain_point_mining":
            # æ ¹æ®å®¢æˆ·éœ€æ±‚æ˜ç¡®ç¨‹åº¦è°ƒæ•´ç­–ç•¥
            if current_customer_intent and current_customer_intent.intent_type == "info_seeking":
                # å¦‚æœå®¢æˆ·å·²ç»è¡¨è¾¾æ˜ç¡®éœ€æ±‚ï¼Œç›´æ¥æä¾›ä¿¡æ¯
                candidate_actions = ["value_display", "needs_analysis"]
            else:
                # å¦åˆ™æ‰è¿›è¡Œéœ€æ±‚æŒ–æ˜
                candidate_actions = ["needs_analysis", "pain_point_test"]
                if trust_level > 0.6:
                    candidate_actions.append("value_display")
        elif new_stage == "solution_visualization":
            candidate_actions = ["value_pitch", "value_display"]
            if customer_intent == "high":
                candidate_actions.append("active_close")
        elif new_stage == "natural_invitation":
            candidate_actions = ["active_close"]
            if customer_intent != "high":
                candidate_actions.append("value_pitch")
    
    # æ™ºèƒ½ç­–ç•¥è°ƒæ•´ï¼šè®©è¡Œä¸ºæ›´è‡ªç„¶å’Œè´´è¿‘çœŸäºº
    
    # 1. æ ¹æ®æƒ…æ„ŸçŠ¶æ€è°ƒæ•´ç­–ç•¥
    if trust_level < 0.3:
        # ä¿¡ä»»åº¦ä½æ—¶ï¼Œä¼˜å…ˆå»ºç«‹å…³ç³»
        candidate_actions = ["rapport_building"]
        internal_monologue.append(f"ä¿¡ä»»åº¦è¿‡ä½ ({trust_level:.2f})ï¼Œä¼˜å…ˆå»ºç«‹å…³ç³»")
    elif comfort_level < 0.2 and new_stage in ["solution_visualization", "natural_invitation"]:
        # èˆ’é€‚åº¦ä½æ—¶ï¼Œå›é€€åˆ°ç¼“è§£å‹åŠ›
        candidate_actions.insert(0, "stress_response")
        internal_monologue.append(f"èˆ’é€‚åº¦è¿‡ä½ ({comfort_level:.2f})ï¼Œä¼˜å…ˆç¼“è§£å‹åŠ›")
    
    # 2. æ„å‘ç­‰çº§ç‰¹æ®Šå¤„ç†
    if customer_intent == "fake_high" and "reverse_probe" not in candidate_actions:
        candidate_actions.append("reverse_probe")  # è¯†åˆ«è™šå‡é«˜æ„å‘
        internal_monologue.append(f"æ£€æµ‹åˆ°è™šå‡é«˜æ„å‘ï¼Œæ·»åŠ åå‘è¯•æ¢")
    elif customer_intent == "low" and new_stage in ["solution_visualization", "natural_invitation"]:
        # ä½æ„å‘å®¢æˆ·ä¸åº”è¯¥è¿›å…¥é«˜å‹é”€å”®é˜¶æ®µ
        candidate_actions = ["rapport_building", "needs_analysis"]
        internal_monologue.append(f"ä½æ„å‘å®¢æˆ·ï¼Œå›é€€åˆ°åŸºç¡€äº¤æµ")
    
    # 3. è‡ªç„¶æœç´¢ç©ºé—´ç®¡ç†
    search_space_size = len(candidate_actions)
    
    if search_space_size == 1:
        # é€‚å½“æ‰©å±•ï¼Œä¿æŒçµæ´»æ€§
        primary_action = candidate_actions[0]
        
        if primary_action == "active_close":
            if comfort_level < 0.6:
                candidate_actions.append("stress_response")
            if trust_level > 0.7:
                candidate_actions.append("value_display")
        elif primary_action in ["value_display", "value_pitch"]:
            candidate_actions.append("needs_analysis")
            if trust_level > 0.6:
                candidate_actions.append("active_close")
        elif primary_action == "stress_response":
            candidate_actions.append("rapport_building")
        
        internal_monologue.append(f"æ‰©å±•æœç´¢ç©ºé—´: {primary_action} â†’ {candidate_actions}")
    
    elif search_space_size > 3:
        # ä¿æŒåˆç†èŒƒå›´
        candidate_actions = candidate_actions[:3]
        internal_monologue.append(f"é™åˆ¶æœç´¢ç©ºé—´ä¸º3ä¸ªé€‰é¡¹")
    
    # ç¡®ä¿è‡³å°‘æœ‰åŸºç¡€å›åº”èƒ½åŠ›
    if not candidate_actions:
        candidate_actions = ["rapport_building"]
        internal_monologue.append(f"å…œåº•ç­–ç•¥ï¼šä½¿ç”¨åŸºç¡€å…³ç³»å»ºç«‹")
    
    final_search_space = len(candidate_actions)
    decision_context = f"é˜¶æ®µ:{new_stage}, æƒ…æ„Ÿ:{customer_intent}, ä¿¡ä»»:{trust_level:.2f}"
    if current_customer_intent:
        decision_context += f", æ„å›¾:{current_customer_intent.intent_type}"
    internal_monologue.append(f"ç­–ç•¥å†³ç­– ({decision_context}) -> å€™é€‰åŠ¨ä½œ: {candidate_actions}")

    # æ„å»ºè¿”å›çŠ¶æ€
    result = {
        "emotional_state": current_emotional_state,
        "current_stage": new_stage,
        "customer_intent_level": customer_intent,
        "candidate_actions": list(set(candidate_actions)),
        "internal_monologue": internal_monologue,
    }
    
    # æ·»åŠ æ–°çš„çŠ¶æ€å­—æ®µ
    if current_customer_intent:
        result["customer_intent"] = current_customer_intent
    if current_appointment_info:
        result["appointment_info"] = current_appointment_info

    return result

def _fallback_evaluation(action: str, response: str, current_stage: str, emotional_state, customer_intent_level: str) -> float:
    """
    åŸºäºè§„åˆ™çš„å…œåº•è¯„ä¼°æœºåˆ¶ï¼Œå½“è¯„ä¼°æ¨¡å‹å¤±è´¥æ—¶ä½¿ç”¨
    """
    score = 0.5  # é»˜è®¤ä¸­ç­‰åˆ†æ•°
    
    # æ£€æŸ¥å›å¤æ˜¯å¦è¿‡çŸ­æˆ–è¿‡é•¿
    if len(response.strip()) < 3:
        return 0.2  # è¿‡çŸ­å›å¤
    if len(response) > 500:
        return 0.4  # è¿‡é•¿å›å¤
    
    # æ ¹æ®é˜¶æ®µè°ƒæ•´åŸºç¡€åˆ†æ•°
    stage_scores = {
        "initial_contact": {"greeting": 0.8, "rapport_building": 0.7},
        "ice_breaking": {"rapport_building": 0.8, "needs_analysis": 0.6},
        "subtle_expertise": {"value_display": 0.8, "needs_analysis": 0.7},
        "pain_point_mining": {"needs_analysis": 0.8, "pain_point_test": 0.7},
        "solution_visualization": {"value_pitch": 0.8, "value_display": 0.7},
        "natural_invitation": {"active_close": 0.8, "value_pitch": 0.6}
    }
    
    if current_stage in stage_scores and action in stage_scores[current_stage]:
        score = stage_scores[current_stage][action]
    
    # æ ¹æ®æƒ…æ„ŸçŠ¶æ€è°ƒæ•´
    trust_level = emotional_state.trust_level if emotional_state else 0.5
    comfort_level = emotional_state.comfort_level if emotional_state else 0.5
    
    # ä¿¡ä»»åº¦ä½æ—¶ï¼Œä¼˜å…ˆå…³ç³»å»ºç«‹
    if trust_level < 0.3:
        if action in ["rapport_building", "greeting"]:
            score += 0.1
        elif action in ["active_close", "value_pitch"]:
            score -= 0.2
    
    # èˆ’é€‚åº¦ä½æ—¶ï¼Œé¿å…å‹åŠ›è¿‡å¤§çš„åŠ¨ä½œ
    if comfort_level < 0.3:
        if action in ["stress_response", "rapport_building"]:
            score += 0.1
        elif action in ["active_close"]:
            score -= 0.1
    
    # æ ¹æ®å®¢æˆ·æ„å‘è°ƒæ•´
    if customer_intent_level == "high" and action == "active_close":
        score += 0.1
    elif customer_intent_level == "low" and action == "active_close":
        score -= 0.2
    
    # ğŸ¯ æ–°å¢ï¼šæ˜ç¡®éœ€æ±‚æ—¶ä¼˜å…ˆæä¾›ä¿¡æ¯
    # ç®€å•çš„å…³é”®è¯æ£€æµ‹æ¥åˆ¤æ–­å›å¤ç±»å‹
    need_keywords = ["æˆ‘æƒ³", "æƒ³äº†è§£", "æƒ³åš", "éœ€è¦", "å’¨è¯¢", "ä»·æ ¼", "å¤šå°‘é’±"]
    
    # æ£€æŸ¥å›å¤æ˜¯å¦ç›´æ¥æä¾›äº†ä¿¡æ¯è€Œä¸æ˜¯ç»§ç»­æé—®
    if action == "value_display":
        if any(keyword in response for keyword in ["é¡¹ç›®", "æ–¹æ³•", "ä»·æ ¼", "æ•ˆæœ", "å¯ä»¥"]):
            score += 0.15  # å¥–åŠ±æä¾›ä¿¡æ¯çš„å›å¤
    elif action == "needs_analysis":
        if any(keyword in response for keyword in ["ä»€ä¹ˆ", "æ€ä¹ˆ", "å“ªç§", "ä¸ºä»€ä¹ˆ"]):
            score -= 0.1  # é™ä½ç»§ç»­æé—®çš„å›å¤åˆ†æ•°
    
    return max(0.1, min(1.0, score))  # ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…

def _generate_and_evaluate_action(
    action: str, 
    state: GraphState, # ä¼ é€’æ•´ä¸ªçŠ¶æ€ä»¥è·å–æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡
) -> tuple:
    """
    ä¸ºå•ä¸ªåŠ¨ä½œç”Ÿæˆå¹¶è¯„ä¼°å›å¤ã€‚è¿™æ˜¯ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œç”¨äºå¹¶è¡Œæ‰§è¡Œã€‚
    """
    # ä» state ä¸­è§£æ„æ‰€éœ€å˜é‡
    messages = state["messages"]
    node_model = state["node_model"]
    agent_temperature = state["agent_temperature"]
    feedback_model = state["feedback_model"]
    current_stage = state["current_stage"]
    emotional_state = state["emotional_state"]
    customer_intent_level = state.get("customer_intent_level", "low")

    try:
        # ä½¿ç”¨å·¥å‚åŠ¨æ€è·å–é‡‡æ ·å™¨
        node_sampler, _ = SamplerFactory.get_sampler_and_cost(node_model)
        
        # block çš„åˆ›å»ºé€»è¾‘ç°åœ¨åªéœ€è¦é‡‡æ ·å™¨å®ä¾‹
        block = create_block(action, node_sampler, node_model)
        if not block:
            return None, f"æ¨¡å— '{action}' åˆ›å»ºå¤±è´¥ï¼Œå·²è·³è¿‡ã€‚"

        # æ‰€æœ‰æ¨¡å—éƒ½ä½¿ç”¨ç»Ÿä¸€çš„forwardæ¥å£
        response = block.forward(messages, agent_temperature)
            
        if response is None:
            return None, f"æ¨¡å— '{action}' æ‰§è¡Œå¤±è´¥ï¼Œå·²è·³è¿‡ã€‚"

        if "[INFO_SUFFICIENT]" in response:
            score, reasoning = 0.0, "å†…éƒ¨æŒ‡ä»¤ï¼Œä¸åº”ç›´æ¥è¾“å‡º"
        else:
            # ğŸ”§ ä¼˜åŒ–è¯„ä¼°é€»è¾‘ï¼šæ›´å®½æ¾çš„è¯„ä¼°æ ‡å‡† + æ›´å¼ºçš„å…œåº•æœºåˆ¶
            try:
                # åŠ¨æ€è·å–è¯„ä¼°æ¨¡å‹çš„é‡‡æ ·å™¨
                feedback_sampler, _ = SamplerFactory.get_sampler_and_cost(feedback_model)
                
                # ğŸ¯ æ”¹è¿›çš„è¯„ä¼°promptï¼šé‡ç‚¹å…³æ³¨éœ€æ±‚æ»¡è¶³
                
                # æ£€æŸ¥æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
                last_user_message = ""
                for msg in reversed(messages):
                    if hasattr(msg, 'content') and not msg.content.startswith("å°æ–‡"):
                        last_user_message = msg.content
                        break
                
                feedback_prompt = f"""
ä½ æ˜¯å¯¹è¯è´¨é‡è¯„ä¼°ä¸“å®¶ã€‚è¯„ä¼°è¿™ä¸ªå›å¤æ˜¯å¦åˆé€‚ã€‚

**å…³é”®åŸåˆ™ï¼šå½“å®¢æˆ·è¡¨è¾¾æ˜ç¡®éœ€æ±‚æ—¶ï¼Œä¼˜å…ˆæ»¡è¶³éœ€æ±‚è€Œä¸æ˜¯ç»§ç»­æŒ–æ˜**

**ç”¨æˆ·æœ€åè¯´ï¼š** "{last_user_message}"

**å€™é€‰å›å¤ (ç­–ç•¥: {action}):**
"{response}"

**è¯„ä¼°è¦ç‚¹ï¼š**
1. å¦‚æœç”¨æˆ·è¯´"æˆ‘æƒ³ç¾ç™½"ã€"æƒ³äº†è§£XX"ç­‰æ˜ç¡®éœ€æ±‚ï¼Œä¼˜å…ˆç»™åˆ†é«˜çš„å›å¤åº”è¯¥æ˜¯ï¼š
   - ç›´æ¥æä¾›ç›¸å…³ä¿¡æ¯/é¡¹ç›®ä»‹ç» (é«˜åˆ†)
   - è€Œä¸æ˜¯ç»§ç»­é—®"æ‚¨æƒ³æ”¹å–„ä»€ä¹ˆé—®é¢˜" (ä½åˆ†)

2. å¦‚æœç”¨æˆ·å·²ç»é€‰æ‹©äº†å…·ä½“é¡¹ç›®ï¼Œä¼˜å…ˆç»™åˆ†é«˜çš„å›å¤åº”è¯¥æ˜¯ï¼š
   - è¿›å…¥é¢„çº¦æµç¨‹/æä¾›æ¡ˆä¾‹ (é«˜åˆ†)
   - è€Œä¸æ˜¯ç»§ç»­äº†è§£éœ€æ±‚ (ä½åˆ†)

**è¯„åˆ†æ ‡å‡†:**
- 0.8-1.0: å›å¤ç›´æ¥æ»¡è¶³äº†ç”¨æˆ·éœ€æ±‚
- 0.6-0.7: å›å¤åŸºæœ¬åˆé€‚ï¼Œç•¥æœ‰åç¦»ä½†å¯æ¥å—
- 0.4-0.5: å›å¤ä¸€èˆ¬ï¼Œæ²¡æœ‰å¾ˆå¥½æ»¡è¶³éœ€æ±‚
- 0.2-0.3: å›å¤åç¦»äº†ç”¨æˆ·æ„å›¾
- 0.0-0.1: å›å¤å®Œå…¨ä¸åˆé€‚

JSONæ ¼å¼: {{"score": æ•°å€¼, "reasoning": "ç®€çŸ­ç†ç”±"}}
"""
                raw_feedback, _ = feedback_sampler(
                    [{"role": "user", "content": feedback_prompt}],
                    temperature=0.1,  # é™ä½æ¸©åº¦æé«˜ç¨³å®šæ€§
                    response_format='json_object'
                )
                
                # å¢å¼ºJSONè§£æé€»è¾‘
                if raw_feedback is None or raw_feedback.strip() == "":
                    raise ValueError("è¯„ä¼°æ¨¡å‹è¿”å›ç©ºå†…å®¹")
                
                # å°è¯•ç›´æ¥è§£æ
                try:
                    feedback_data = json.loads(raw_feedback)
                except json.JSONDecodeError:
                    # ä½¿ç”¨æ­£åˆ™æå–JSON
                    import re
                    match = re.search(r'\{.*?\}', raw_feedback, re.DOTALL)
                    if match:
                        feedback_data = json.loads(match.group(0))
                    else:
                        raise ValueError("æ— æ³•æ‰¾åˆ°æœ‰æ•ˆJSON")

                score = float(feedback_data.get("score", 0.5))  # é»˜è®¤ç»™ä¸­ç­‰åˆ†
                reasoning = feedback_data.get("reasoning", "è¯„ä¼°æˆåŠŸ")
                
                # ç¡®ä¿åˆ†æ•°åœ¨åˆç†èŒƒå›´å†…
                score = max(0.0, min(1.0, score))

            except Exception as eval_error:
                # ğŸ›¡ï¸ å¼ºåŒ–å…œåº•ç­–ç•¥ï¼šåŸºäºè§„åˆ™çš„å¿«é€Ÿè¯„ä¼°
                score = _fallback_evaluation(action, response, current_stage, emotional_state, customer_intent_level)
                reasoning = f"è¯„ä¼°æ¨¡å‹å¤±è´¥ï¼Œä½¿ç”¨è§„åˆ™è¯„ä¼°: {eval_error}"

        evaluated_response = {
            "action": action,
            "response": response,
            "score": score,
            "reasoning": reasoning
        }
        monologue_entry = f"  - [{action}] ç”Ÿæˆå›å¤: '{response[:30]}...' -> è¯„ä¼°å¾—åˆ†: {score} (åŸå› : {reasoning})"
        return evaluated_response, monologue_entry

    except Exception as e:
        return None, f"  - [{action}] å¤„ç†æ—¶å‡ºç°å¼‚å¸¸: {e}"


def generate_and_evaluate_node(state: GraphState) -> Dict[str, Any]:
    """
    å¹¶è¡Œåœ°ä¸ºæ¯ä¸ªå€™é€‰åŠ¨ä½œç”Ÿæˆå›å¤å¹¶è·å–åé¦ˆã€‚
    """
    internal_monologue = state.get("internal_monologue", [])
    candidate_actions = state.get("candidate_actions", [])
    
    evaluated_responses = []
    new_monologue = list(internal_monologue)

    # é™åˆ¶å¹¶å‘æ•°é‡ï¼Œé¿å…APIæœåŠ¡å™¨è¿‡è½½å’ŒCancelledError
    max_concurrent_requests = min(3, len(candidate_actions) or 1)
    with ThreadPoolExecutor(max_workers=max_concurrent_requests) as executor:
        future_to_action = {
            executor.submit(
                _generate_and_evaluate_action, 
                action, 
                state, # ä¼ é€’æ•´ä¸ªçŠ¶æ€ä»¥æä¾›æ›´ä¸°å¯Œçš„è¯„ä¼°ä¸Šä¸‹æ–‡
            ): action for action in candidate_actions
        }

        for future in as_completed(future_to_action):
            try:
                evaluated_response, monologue_entry = future.result()
                if evaluated_response:
                    evaluated_responses.append(evaluated_response)
                if monologue_entry:
                    new_monologue.append(monologue_entry)
            except Exception as e:
                action = future_to_action[future]
                new_monologue.append(f"  - [{action}] åœ¨å¹¶è¡Œæ‰§è¡Œä¸­æ•è·åˆ°è‡´å‘½é”™è¯¯: {e}")

    verbose = state.get("verbose", False)
    if verbose:
        print(f"[DEBUG] ç”Ÿæˆè¯„ä¼°èŠ‚ç‚¹: è¯„ä¼°äº† {len(evaluated_responses)} ä¸ªå€™é€‰å›å¤")

    if not evaluated_responses:
        new_monologue.append("æ‰€æœ‰æ¨¡å—éƒ½æ‰§è¡Œå¤±è´¥äº†ï¼Œä½¿ç”¨ç´§æ€¥å…œåº•å›å¤")
        # ğŸ›¡ï¸ å¤šçº§å…œåº•æœºåˆ¶
        try:
            # å°è¯•äººå·¥è½¬æ¥
            node_sampler, _ = SamplerFactory.get_sampler_and_cost(state["node_model"])
            block = create_block("human_handoff", node_sampler, state["node_model"])
            final_response = block.forward(state.get("messages", []), state.get("agent_temperature", 0.5))
        except Exception as e:
            new_monologue.append(f"äººå·¥è½¬æ¥æ¨¡å—ä¹Ÿå¤±è´¥äº†: {e}")
            # æœ€ç»ˆå…œåº•ï¼šå›ºå®šå›å¤
            final_response = "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹é—®é¢˜ï¼Œèƒ½ç¨åå†è”ç³»æˆ‘å—ï¼Ÿ"
        
        return {
            "final_response": final_response, 
            "last_message": final_response,
            "internal_monologue": new_monologue
        }

    return {
        "evaluated_responses": evaluated_responses,
        "internal_monologue": new_monologue,
    }

def self_verification_node(state: GraphState) -> Dict[str, Any]:
    """
    ä»è¯„ä¼°è¿‡çš„å€™é€‰é¡¹ä¸­é€‰æ‹©æœ€ä½³å“åº”ã€‚
    """
    evaluated_responses = state.get("evaluated_responses", [])
    messages = state.get("messages", [])
    internal_monologue = state.get("internal_monologue", [])
    
    # ä¸å†éœ€è¦ä»è¿™é‡Œè·å–é‡‡æ ·å™¨ï¼Œå› ä¸ºè¯„åˆ†å·²åœ¨ generate_and_evaluate_node å®Œæˆ
    # sampler = ...

    # ğŸ”§ ä¼˜åŒ–é€‰æ‹©é€»è¾‘ï¼šé™ä½è´¨é‡é—¨æ§›ï¼Œç¡®ä¿æ€»æ˜¯æœ‰å›å¤
    
    # å…ˆå°è¯•0.3ä»¥ä¸Šçš„å›å¤
    high_quality_responses = [r for r in evaluated_responses if r.get('score', 0.0) > 0.3]
    
    # å¦‚æœæ²¡æœ‰0.3ä»¥ä¸Šçš„ï¼Œå°è¯•0.2ä»¥ä¸Šçš„
    if not high_quality_responses:
        high_quality_responses = [r for r in evaluated_responses if r.get('score', 0.0) > 0.2]
    
    # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œé€‰æ‹©æ‰€æœ‰å›å¤ä¸­å¾—åˆ†æœ€é«˜çš„
    if not high_quality_responses and evaluated_responses:
        high_quality_responses = sorted(evaluated_responses, key=lambda x: x.get('score', 0.0), reverse=True)
    
    # æç«¯æƒ…å†µï¼šæ²¡æœ‰ä»»ä½•å›å¤
    if not high_quality_responses:
        new_monologue = internal_monologue + ["è‡ªæˆ‘éªŒè¯å¤±è´¥ï¼šæ²¡æœ‰å¯ä¾›é€‰æ‹©çš„å€™é€‰å›å¤ï¼Œä½¿ç”¨ç´§æ€¥å›å¤"]
        fallback_response = "å—¯å—¯ï¼Œå¥½çš„"  # ç®€å•è‡ªç„¶çš„å…œåº•å›å¤
        return {
            "final_response": fallback_response,
            "last_message": fallback_response,
            "messages": [AIMessage(content=fallback_response)],
            "internal_monologue": new_monologue
        }

    if len(high_quality_responses) == 1:
        final_response = high_quality_responses[0]['response']
        new_monologue = internal_monologue + [f"è‡ªæˆ‘éªŒè¯ï¼šåªæœ‰1ä¸ªé«˜è´¨é‡é€‰é¡¹ï¼Œç›´æ¥é€‰æ‹© '{high_quality_responses[0]['action']}'ã€‚"]
    else:
        # ç›´æ¥æŒ‰å¾—åˆ†æ’åºé€‰æ‹©æœ€é«˜åˆ†çš„å›å¤
        best_response = sorted(high_quality_responses, key=lambda x: x['score'], reverse=True)[0]
        final_response = best_response['response']
        new_monologue = internal_monologue + [
            f"è‡ªæˆ‘éªŒè¯ï¼šä» {len(high_quality_responses)} ä¸ªé€‰é¡¹ä¸­é€‰æ‹©å¾—åˆ†æœ€é«˜çš„å›å¤ (æ¨¡å—: {best_response['action']}, å¾—åˆ†: {best_response['score']:.2f})ã€‚"
        ]

    # --- å…³é”®æ”¹åŠ¨ï¼šå°†AIçš„æœ€ç»ˆå›å¤æ›´æ–°å›æ¶ˆæ¯å†å²ä¸­ ---
    # With `add_messages`, we just need to return the new message(s) in a list.
    # LangGraph will handle appending it to the state.
    new_monologue.append("å°†AIçš„æœ€æ–°å›å¤è¿”å›ï¼Œç”±LangGraphè‡ªåŠ¨æ›´æ–°å†å²ã€‚")

    verbose = state.get("verbose", False)
    if verbose:
        print(f"[DEBUG] æœ€ç»ˆå›å¤: {final_response}")

    # --- æ–°å¢ï¼šå¦‚æœ verbose æ¨¡å¼å¼€å¯ï¼Œåˆ™å‡†å¤‡è°ƒè¯•ä¿¡æ¯ ---
    debug_info = None
    if state.get("verbose", False):
        from common import DebugInfo
        debug_info = DebugInfo(
            current_stage=state.get("current_stage"),
            emotional_state=state.get("emotional_state").model_dump() if state.get("emotional_state") else None,
            internal_monologue=new_monologue,
        )

    return {
        "final_response": final_response, # ä¿ç•™æ­¤å­—æ®µç”¨äºæœ¬åœ°æµ‹è¯•çš„å³æ—¶æ‰“å°
        "last_message": final_response,   # æ–°å¢ï¼šç”¨äºAPIè¾“å‡º
        "messages": [AIMessage(content=final_response)], # åªè¿”å›æ–°å¢çš„æ¶ˆæ¯
        "internal_monologue": new_monologue,
        "debug_info": debug_info, # å°†è°ƒè¯•ä¿¡æ¯æ·»åŠ åˆ°è¿”å›å­—å…¸ä¸­
    }



def build_graph():
    """æ„å»ºå¹¶ç¼–è¯‘ LangGraph çŠ¶æ€å›¾ã€‚"""
    # ä½¿ç”¨MasAgentOutputæ§åˆ¶APIå“åº”æ ¼å¼ï¼Œä»¿ç…§huanmu_agent-testçš„è®¾è®¡
    workflow = StateGraph(GraphState, output=MasAgentOutput)

    workflow.add_node("initialize_state", initialize_state_node)
    workflow.add_node("analyze_sentiment", analyze_sentiment_node)
    workflow.add_node("meta_design", _design_node)
    workflow.add_node("generate_and_evaluate", generate_and_evaluate_node)
    workflow.add_node("self_verify", self_verification_node)

    workflow.set_entry_point("initialize_state")

    workflow.add_edge("initialize_state", "analyze_sentiment")
    workflow.add_edge("analyze_sentiment", "meta_design")
    workflow.add_edge("meta_design", "generate_and_evaluate")
    workflow.add_edge("generate_and_evaluate", "self_verify")
    workflow.add_edge("self_verify", END)
    
    return workflow

app = build_graph().compile()

if __name__ == "__main__":
    print("é‡æ„åçš„ MAS-Zero (LangGraph ç‰ˆæœ¬)")
    
    # For local testing, compile with a checkpointer
    try:
        from langgraph.checkpoint.memory import MemorySaver
        memory = MemorySaver()
        local_app = build_graph().compile(checkpointer=memory)
    except ImportError:
        # In cloud deployment, checkpointer is provided automatically
        local_app = build_graph().compile()

    config = {"configurable": {"thread_id": "user-123-cli-session"}}
    
    print("\næ‚¨å¥½ï¼Œæˆ‘æ˜¯æ—åŒ»ç”Ÿã€‚è¯·é—®æ‚¨ä¸»è¦æƒ³äº†è§£å“ªäº›å£è…”æ–¹é¢çš„é—®é¢˜å‘¢ï¼Ÿ")

    while True:
        user_input = input("ä½ : ")
        if user_input.lower() in ["é€€å‡º", "exit"]:
            print("å†è§ï¼")
            break
        
        # ä½¿ç”¨æ–°çš„ user_input å­—æ®µä½œä¸ºè¾“å…¥
        inputs = {"user_input": user_input}
        
        # stream() æ–¹æ³•å¯ä»¥è®©æˆ‘ä»¬å®æ—¶çœ‹åˆ°æ¯ä¸€æ­¥çš„çŠ¶æ€æ›´æ–°
        # åœ¨è¿™é‡Œæˆ‘ä»¬ä¸å…³å¿ƒ stream çš„ä¸­é—´äº§ç‰©ï¼Œåªå…³å¿ƒæœ€ç»ˆçŠ¶æ€
        for _ in local_app.stream(inputs, config=config):
            pass


        # ä» checkpointer è·å–æœ€ç»ˆçš„ã€æœ€å®Œæ•´çš„çŠ¶æ€
        snapshot = local_app.get_state(config)
        final_state_values = snapshot.values
        
        response = final_state_values.get("final_response", "æŠ±æ­‰ï¼Œæˆ‘å¥½åƒèµ°ç¥äº†ï¼Œèƒ½å†è¯´ä¸€éå—ï¼Ÿ")
        print(f"æ—åŒ»ç”Ÿ: {response}")
        
        print("\n--- å†…éƒ¨çŠ¶æ€ (ä»…ä¾›è°ƒè¯•) ---")
        # ç›´æ¥è®¿é—®çŠ¶æ€ä¸­çš„å€¼
        current_stage = final_state_values.get('current_stage')
        emotional_state = final_state_values.get('emotional_state')
        internal_monologue = final_state_values.get('internal_monologue', [])

        print(f"å½“å‰é˜¶æ®µ: {current_stage}")
        if emotional_state:
            print(f"æƒ…æ„ŸçŠ¶æ€: {emotional_state}")
        else:
            print("æƒ…æ„ŸçŠ¶æ€: (æœªè¯„ä¼°)")
            
        print("å†…å¿ƒç‹¬ç™½:")
        if isinstance(internal_monologue, list):
            for line in internal_monologue:
                print(f"- {line}")
        print("----------------\n")